{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_model = pd.read_csv('Duffey_Tyler_2022_FF.csv')\n",
    "sim_model = sim_model[['pitch_type', 'release_speed', 'release_spin_rate', 'release_pos_z', 'release_pos_x', 'spin_axis',\n",
    "                                               'plate_z', 'plate_x', 'pfx_x', 'pfx_z', 'vx0', 'vy0', 'vz0', 'ax', 'ay', 'az']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "## CALCULATE SPIN X, SPIN Y, SPIN Z ##\n",
    "######################################\n",
    "\n",
    "def calculate_spin_components(data):\n",
    "    \n",
    "    # Extract necessary columns from the data\n",
    "    vx0 = data[\"vx0\"]\n",
    "    vy0 = data[\"vy0\"]\n",
    "    vz0 = data[\"vz0\"]\n",
    "    ax = data[\"ax\"]\n",
    "    ay = data[\"ay\"]\n",
    "    az = data[\"az\"]\n",
    "    \n",
    "    # Calculate velocity and acceleration magnitudes\n",
    "    velocity_magnitude = np.sqrt(vx0**2 + vy0**2 + vz0**2)\n",
    "    acceleration_magnitude = np.sqrt(ax**2 + ay**2 + az**2)\n",
    "    \n",
    "    # Calculate velocity and acceleration unit vectors\n",
    "    velocity_unit_x = vx0 / velocity_magnitude\n",
    "    velocity_unit_y = vy0 / velocity_magnitude\n",
    "    velocity_unit_z = vz0 / velocity_magnitude\n",
    "    acceleration_unit_x = ax / acceleration_magnitude\n",
    "    acceleration_unit_y = ay / acceleration_magnitude\n",
    "    acceleration_unit_z = az / acceleration_magnitude\n",
    "\n",
    "    # Calculate spin axis components\n",
    "    SpinX = velocity_unit_y * acceleration_unit_z - velocity_unit_z * acceleration_unit_y\n",
    "    SpinY = velocity_unit_z * acceleration_unit_x - velocity_unit_x * acceleration_unit_z\n",
    "    SpinZ = velocity_unit_x * acceleration_unit_y - velocity_unit_y * acceleration_unit_x\n",
    "    \n",
    "    # Normalize spin axis components\n",
    "    spin_magnitude = np.sqrt(SpinX**2 + SpinY**2 + SpinZ**2)\n",
    "    SpinX = SpinX / spin_magnitude\n",
    "    SpinY = SpinY / spin_magnitude\n",
    "    SpinZ = SpinZ / spin_magnitude\n",
    "    \n",
    "    return SpinX, SpinY, SpinZ\n",
    "\n",
    "spin_x, spin_y, spin_z = calculate_spin_components(sim_model)\n",
    "    \n",
    "# Add spin axis components to the DataFrame\n",
    "sim_model[\"SpinX\"] = spin_x\n",
    "sim_model[\"SpinY\"] = spin_y\n",
    "sim_model[\"SpinZ\"] = spin_z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_spin_axis(data):\n",
    "    SpinX = data[\"SpinX\"]\n",
    "    SpinY = data[\"SpinY\"]\n",
    "    SpinZ = data[\"SpinZ\"]\n",
    "    \n",
    "    spin = np.column_stack((SpinX, SpinY, SpinZ))\n",
    "    \n",
    "    return spin\n",
    "\n",
    "spin = calculate_spin_axis(sim_model)\n",
    "\n",
    "# Add spin axis to the DataFrame\n",
    "sim_model[\"spin\"] = list(spin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSimpleLatLon(spin):\n",
    "    spinAxis = spin / (np.linalg.norm(spin) + 1e-9)\n",
    "    \n",
    "    # Assume an identity matrix for hawkeyeRotMat\n",
    "    hawkeyeRotMat = np.eye(3)\n",
    "    inverseHawkeyeRotMat = hawkeyeRotMat  # Identity matrix is its own inverse\n",
    "    \n",
    "    # Rotate the spin axis from global coordinates to local coordinates\n",
    "    rotatedSpinAxis = np.dot(inverseHawkeyeRotMat, spinAxis)\n",
    "    \n",
    "    # Convert between Trajekt and Hawkeye reference frames (x = -z, y = x, z = -y)\n",
    "    x, y, z = -rotatedSpinAxis[2], rotatedSpinAxis[0], -rotatedSpinAxis[1]\n",
    "    \n",
    "    return {\n",
    "        \"lon\": np.degrees(np.arctan2(y, x)),\n",
    "        \"lat\": np.degrees(np.pi/2 - np.arccos(z))\n",
    "    }\n",
    "    \n",
    "sim_model[\"SeamLat\"] = sim_model[\"spin\"].apply(lambda spin: getSimpleLatLon(np.array(spin))[\"lat\"])\n",
    "sim_model[\"SeamLon\"] = sim_model[\"spin\"].apply(lambda spin: getSimpleLatLon(np.array(spin))[\"lon\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  pitch_type  release_speed  release_spin_rate  release_pos_z  release_pos_x  \\\n",
      "0         FF           90.0               2168           6.23          -2.39   \n",
      "1         FF           90.7               2230           6.10          -2.50   \n",
      "2         FF           90.9               2269           6.16          -2.60   \n",
      "3         FF           90.9               2138           6.16          -2.52   \n",
      "4         FF           90.4               2208           6.08          -2.65   \n",
      "\n",
      "   spin_axis  plate_z  plate_x  pfx_x  pfx_z  ...       vz0        ax  \\\n",
      "0        201     3.02     0.61   0.09   1.11  ... -4.341588 -0.548144   \n",
      "1        210     2.78    -0.36  -0.19   1.45  ... -5.554115 -3.374833   \n",
      "2        202     3.28     0.01  -0.18   1.28  ... -4.161636 -3.300812   \n",
      "3        206     3.72     0.43  -0.16   1.25  ... -2.981592 -3.234983   \n",
      "4        201     3.51    -0.52  -0.16   1.17  ... -3.000728 -3.062860   \n",
      "\n",
      "          ay         az     SpinX     SpinY     SpinZ  \\\n",
      "0  27.587603 -18.734218  0.997317  0.053643  0.049813   \n",
      "1  25.714978 -14.136747  0.988043  0.049377 -0.146056   \n",
      "2  22.876869 -16.304028  0.990923  0.055820 -0.122293   \n",
      "3  23.300726 -16.916864  0.992462  0.060348 -0.106666   \n",
      "4  26.447127 -18.131071  0.993756  0.045132 -0.102042   \n",
      "\n",
      "                                                spin   SeamLat    SeamLon  \n",
      "0  [0.9973169582736926, 0.053642887346654955, 0.0... -3.074987  92.859371  \n",
      "1  [0.9880433321191531, 0.049376992466063564, -0.... -2.830244  81.591248  \n",
      "2  [0.9909230764844319, 0.05581965089276674, -0.1... -3.199894  82.964508  \n",
      "3  [0.9924618657861707, 0.06034777394034349, -0.1... -3.459775  83.865628  \n",
      "4  [0.9937557952144052, 0.045131808694544175, -0.... -2.586741  84.137244  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "print(sim_model.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  pitch_type  release_speed  release_spin_rate  release_pos_z  release_pos_x  \\\n",
      "0         FF           90.0               2168           6.23          -2.39   \n",
      "1         FF           90.7               2230           6.10          -2.50   \n",
      "2         FF           90.9               2269           6.16          -2.60   \n",
      "3         FF           90.9               2138           6.16          -2.52   \n",
      "4         FF           90.4               2208           6.08          -2.65   \n",
      "\n",
      "   spin_axis   SeamLat    SeamLon  pfx_x  pfx_z  \n",
      "0        201 -3.074987  92.859371   0.09   1.11  \n",
      "1        210 -2.830244  81.591248  -0.19   1.45  \n",
      "2        202 -3.199894  82.964508  -0.18   1.28  \n",
      "3        206 -3.459775  83.865628  -0.16   1.25  \n",
      "4        201 -2.586741  84.137244  -0.16   1.17  \n"
     ]
    }
   ],
   "source": [
    "sim_model = sim_model[['pitch_type', 'release_speed', 'release_spin_rate', 'release_pos_z', 'release_pos_x', 'spin_axis',\n",
    "                                               'SeamLat', 'SeamLon', 'pfx_x', 'pfx_z']]\n",
    "print(sim_model.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = ['release_pos_x', 'release_pos_z', 'release_speed', 'release_spin_rate', 'SeamLat', 'SeamLon']\n",
    "target = ['pfx_x', 'pfx_z']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "sim_model[features] = scaler.fit_transform(sim_model[features])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "sim_model['pitch_type'] = label_encoder.fit_transform(sim_model['pitch_type'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sim_model[features], sim_model[target], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define the input shape based on the number of features\n",
    "input_shape = (len(features),)\n",
    "\n",
    "# Create a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first hidden layer with 64 units and ReLU activation\n",
    "model.add(Dense(64, activation='relu', input_shape=input_shape))\n",
    "\n",
    "# Add additional hidden layers as needed\n",
    "model.add(Dense(64, activation='relu')) #########\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Add the output layer with 2 units (for pfx_x and pfx_z) and linear activation\n",
    "model.add(Dense(2, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Create an early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor the validation loss\n",
    "    min_delta=0.001,     # Minimum change in the monitored quantity to qualify as an improvement\n",
    "    patience=10,         # Number of epochs with no improvement after which training will be stopped\n",
    "    verbose=1,           # Verbosity mode (0 = silent, 1 = progress bar)\n",
    "    mode='min',          # In 'min' mode, training will stop when the quantity monitored has stopped decreasing\n",
    "    restore_best_weights=True  # Restore the weights from the epoch with the best value of the monitored quantity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.7470 - val_loss: 0.2430\n",
      "Epoch 2/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1442 - val_loss: 0.0665\n",
      "Epoch 3/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0728 - val_loss: 0.0524\n",
      "Epoch 4/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0523 - val_loss: 0.0588\n",
      "Epoch 5/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0484 - val_loss: 0.0443\n",
      "Epoch 6/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0375 - val_loss: 0.0403\n",
      "Epoch 7/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0332 - val_loss: 0.0395\n",
      "Epoch 8/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0322 - val_loss: 0.0336\n",
      "Epoch 9/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0237 - val_loss: 0.0320\n",
      "Epoch 10/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0278 - val_loss: 0.0290\n",
      "Epoch 11/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0255 - val_loss: 0.0294\n",
      "Epoch 12/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0254 - val_loss: 0.0259\n",
      "Epoch 13/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0192 - val_loss: 0.0250\n",
      "Epoch 14/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0173 - val_loss: 0.0237\n",
      "Epoch 15/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0178 - val_loss: 0.0220\n",
      "Epoch 16/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0183 - val_loss: 0.0219\n",
      "Epoch 17/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0173 - val_loss: 0.0212\n",
      "Epoch 18/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0166 - val_loss: 0.0210\n",
      "Epoch 19/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0153 - val_loss: 0.0199\n",
      "Epoch 20/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0133 - val_loss: 0.0188\n",
      "Epoch 21/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0129 - val_loss: 0.0191\n",
      "Epoch 22/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0122 - val_loss: 0.0181\n",
      "Epoch 23/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - val_loss: 0.0183\n",
      "Epoch 24/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0126 - val_loss: 0.0178\n",
      "Epoch 25/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0125 - val_loss: 0.0168\n",
      "Epoch 26/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0122 - val_loss: 0.0173\n",
      "Epoch 27/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0107 - val_loss: 0.0167\n",
      "Epoch 28/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0162\n",
      "Epoch 29/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0103 - val_loss: 0.0170\n",
      "Epoch 30/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0102 - val_loss: 0.0161\n",
      "Epoch 31/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0153\n",
      "Epoch 32/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0100 - val_loss: 0.0153\n",
      "Epoch 33/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0099 - val_loss: 0.0163\n",
      "Epoch 34/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0112 - val_loss: 0.0151\n",
      "Epoch 35/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - val_loss: 0.0151\n",
      "Epoch 36/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0144\n",
      "Epoch 37/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0093 - val_loss: 0.0152\n",
      "Epoch 38/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0098 - val_loss: 0.0145\n",
      "Epoch 39/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0146\n",
      "Epoch 40/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0159\n",
      "Epoch 41/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0141\n",
      "Epoch 42/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0148\n",
      "Epoch 43/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0087 - val_loss: 0.0140\n",
      "Epoch 44/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0146\n",
      "Epoch 45/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0152\n",
      "Epoch 46/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0146\n",
      "Epoch 47/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094 - val_loss: 0.0145\n",
      "Epoch 48/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0076 - val_loss: 0.0141\n",
      "Epoch 49/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0081 - val_loss: 0.0145\n",
      "Epoch 50/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0139\n",
      "Epoch 51/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0139\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fe4844b3110>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "\n",
    "csv_logger = CSVLogger('training_log.csv', append=True, separator=',')\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=16, validation_split=0.2, callbacks=[early_stopping, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the entire model in a single file\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0122\n",
      "Test loss: 0.012236538343131542\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the testing set\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(\"Test loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  pitch_type  release_speed  release_spin_rate  release_pos_z  release_pos_x  \\\n",
      "0         FF           93.1               2265           6.06          -2.65   \n",
      "1         FF           92.7               2259           6.06          -2.66   \n",
      "2         FF           92.7               2314           6.21          -2.60   \n",
      "3         FF           94.4               2269           6.20          -2.65   \n",
      "4         FF           92.7               2162           6.28          -2.69   \n",
      "\n",
      "   spin_axis   SeamLat    SeamLon  pfx_x  pfx_z  \n",
      "0        214 -4.654379  70.613116  -0.43   1.42  \n",
      "1        214 -4.191090  71.599232  -0.40   1.45  \n",
      "2        212 -4.517261  68.650477  -0.43   1.54  \n",
      "3        213 -3.009771  59.217537  -0.58   1.59  \n",
      "4        222 -4.348771  65.168437  -0.59   1.37  \n"
     ]
    }
   ],
   "source": [
    "Duffey_Tyler_2021_FF = pd.read_csv('Duffey_Tyler_2021_FF.csv')\n",
    "print(Duffey_Tyler_2021_FF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "new_features = ['release_pos_x', 'release_pos_z', 'release_speed', 'release_spin_rate', 'SeamLat', 'SeamLon']\n",
    "new_target = ['pfx_x', 'pfx_z']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "Duffey_Tyler_2021_FF[new_features] = scaler.fit_transform(Duffey_Tyler_2021_FF[new_features])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "Duffey_Tyler_2021_FF['pitch_type'] = label_encoder.fit_transform(Duffey_Tyler_2021_FF['pitch_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/15\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "     pfx_x  pfx_z  predicted_pfx_x  predicted_pfx_z\n",
      "0    -0.43   1.42        -0.350564         1.222968\n",
      "1    -0.40   1.45        -0.320483         1.227438\n",
      "2    -0.43   1.54        -0.420627         1.356235\n",
      "3    -0.58   1.59        -0.698609         1.508150\n",
      "4    -0.59   1.37        -0.524806         1.394786\n",
      "..     ...    ...              ...              ...\n",
      "464  -0.62   1.39        -0.581396         1.444116\n",
      "465  -0.79   1.25        -0.634746         1.504727\n",
      "466  -0.53   1.32        -0.425030         1.414663\n",
      "467  -0.65   1.47        -0.692578         1.512535\n",
      "468  -0.69   1.45        -0.695304         1.517622\n",
      "\n",
      "[469 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(Duffey_Tyler_2021_FF[new_features])\n",
    "\n",
    "Duffey_Tyler_2021_FF['predicted_pfx_x'] = predictions[:, 0]\n",
    "Duffey_Tyler_2021_FF['predicted_pfx_z'] = predictions[:, 1]\n",
    "\n",
    "print(Duffey_Tyler_2021_FF[['pfx_x', 'pfx_z', 'predicted_pfx_x', 'predicted_pfx_z']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for pfx_x: 0.011365540424360575\n",
      "MSE for pfx_z: 0.01845781937663172\n",
      "MAE for pfx_x: 0.09473035625239679\n",
      "MAE for pfx_z: 0.10811287869776744\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "mse_x = mean_squared_error(Duffey_Tyler_2021_FF['pfx_x'], Duffey_Tyler_2021_FF['predicted_pfx_x'])\n",
    "mse_z = mean_squared_error(Duffey_Tyler_2021_FF['pfx_z'], Duffey_Tyler_2021_FF['predicted_pfx_z'])\n",
    "\n",
    "mae_x = mean_absolute_error(Duffey_Tyler_2021_FF['pfx_x'], Duffey_Tyler_2021_FF['predicted_pfx_x'])\n",
    "mae_z = mean_absolute_error(Duffey_Tyler_2021_FF['pfx_z'], Duffey_Tyler_2021_FF['predicted_pfx_z'])\n",
    "\n",
    "print(\"MSE for pfx_x:\", mse_x)\n",
    "print(\"MSE for pfx_z:\", mse_z)\n",
    "print(\"MAE for pfx_x:\", mae_x)\n",
    "print(\"MAE for pfx_z:\", mae_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  pitch_type  release_speed  release_spin_rate  release_pos_z  release_pos_x  \\\n",
      "0         FF           95.7               2247           6.10          -2.62   \n",
      "1         FF           94.7               2254           6.23          -2.59   \n",
      "2         FF           94.0               2177           6.30          -2.31   \n",
      "3         FF           95.4               2303           6.34          -2.45   \n",
      "4         FF           95.6               2484           6.18          -2.60   \n",
      "\n",
      "   spin_axis   SeamLat    SeamLon  pfx_x  pfx_z  \n",
      "0        207 -4.254315  64.704574  -0.61   1.18  \n",
      "1        208 -3.400609  71.076774  -0.53   1.00  \n",
      "2        195 -4.789967  76.465145  -0.33   1.18  \n",
      "3        200 -4.623492  67.067328  -0.49   1.37  \n",
      "4        207 -4.482592  62.622096  -0.64   1.27  \n"
     ]
    }
   ],
   "source": [
    "Duffey_Tyler_2019_FF = pd.read_csv('Duffey_Tyler_2019_FF.csv')\n",
    "print(Duffey_Tyler_2019_FF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "newer_features = ['release_pos_x', 'release_pos_z', 'release_speed', 'release_spin_rate', 'SeamLat', 'SeamLon']\n",
    "newer_target = ['pfx_x', 'pfx_z']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "Duffey_Tyler_2019_FF[newer_features] = scaler.fit_transform(Duffey_Tyler_2019_FF[newer_features])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "Duffey_Tyler_2019_FF['pitch_type'] = label_encoder.fit_transform(Duffey_Tyler_2019_FF['pitch_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step\n",
      "     pfx_x  pfx_z  predicted_pfx_x  predicted_pfx_z\n",
      "0    -0.61   1.18        -0.461634         1.381389\n",
      "1    -0.53   1.00        -0.325304         1.385399\n",
      "2    -0.33   1.18        -0.205078         1.316329\n",
      "3    -0.49   1.37        -0.447188         1.481485\n",
      "4    -0.64   1.27        -0.523192         1.463440\n",
      "..     ...    ...              ...              ...\n",
      "498  -0.47   1.23        -0.336223         1.294175\n",
      "499  -0.27   1.26        -0.190672         1.127833\n",
      "500  -0.67   1.33        -0.559978         1.477866\n",
      "501  -0.29   1.27        -0.195267         1.337080\n",
      "502  -0.65   1.15        -0.490081         1.493265\n",
      "\n",
      "[503 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(Duffey_Tyler_2019_FF[new_features])\n",
    "\n",
    "Duffey_Tyler_2019_FF['predicted_pfx_x'] = predictions[:, 0]\n",
    "Duffey_Tyler_2019_FF['predicted_pfx_z'] = predictions[:, 1]\n",
    "\n",
    "print(Duffey_Tyler_2019_FF[['pfx_x', 'pfx_z', 'predicted_pfx_x', 'predicted_pfx_z']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for pfx_x: 0.01619278953603682\n",
      "MSE for pfx_z: 0.03131136755686647\n",
      "MAE for pfx_x: 0.116747777851865\n",
      "MAE for pfx_z: 0.14233711901526327\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "mse_x = mean_squared_error(Duffey_Tyler_2019_FF['pfx_x'], Duffey_Tyler_2019_FF['predicted_pfx_x'])\n",
    "mse_z = mean_squared_error(Duffey_Tyler_2019_FF['pfx_z'], Duffey_Tyler_2019_FF['predicted_pfx_z'])\n",
    "\n",
    "mae_x = mean_absolute_error(Duffey_Tyler_2019_FF['pfx_x'], Duffey_Tyler_2019_FF['predicted_pfx_x'])\n",
    "mae_z = mean_absolute_error(Duffey_Tyler_2019_FF['pfx_z'], Duffey_Tyler_2019_FF['predicted_pfx_z'])\n",
    "\n",
    "print(\"MSE for pfx_x:\", mse_x)\n",
    "print(\"MSE for pfx_z:\", mse_z)\n",
    "print(\"MAE for pfx_x:\", mae_x)\n",
    "print(\"MAE for pfx_z:\", mae_z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
